.extern .func  (.param .b32 func_retval0) dummy
(
.param .b64 dummy_param_0,
.param .b32 dummy_param_1
)
;
.visible .func  (.param .b32 func_retval0) _ZN8__main__11complicatedB2v1B96cw51cXTLSUwHBinCqbbgUAAGBlq82ILSCEQYkgSQBFCjFSaBZJtttTo4sahbKUBDUB3kNVDaQRKChQ_2bSEFA_2fkGdcqwkAE6RecordILi439EE(
.param .b64 _ZN8__main__11complicatedB2v1B96cw51cXTLSUwHBinCqbbgUAAGBlq82ILSCEQYkgSQBFCjFSaBZJtttTo4sahbKUBDUB3kNVDaQRKChQ_2bSEFA_2fkGdcqwkAE6RecordILi439EE_param_0,
.param .b64 _ZN8__main__11complicatedB2v1B96cw51cXTLSUwHBinCqbbgUAAGBlq82ILSCEQYkgSQBFCjFSaBZJtttTo4sahbKUBDUB3kNVDaQRKChQ_2bSEFA_2fkGdcqwkAE6RecordILi439EE_param_1
)
{
.local .align 4 .b8 	__local_depot0[4];
.reg .b64 	%SP;
.reg .b64 	%SPL;
.reg .pred 	%p<4>;
.reg .b16 	%rs<3>;
.reg .f32 	%f<2>;
.reg .b32 	%r<4>;
.reg .f64 	%fd<7>;
.reg .b64 	%rd<107>;
mov.u64 	%SPL, __local_depot0;
cvta.local.u64 	%SP, %SPL;
ld.param.u64 	%rd3, [_ZN8__main__11complicatedB2v1B96cw51cXTLSUwHBinCqbbgUAAGBlq82ILSCEQYkgSQBFCjFSaBZJtttTo4sahbKUBDUB3kNVDaQRKChQ_2bSEFA_2fkGdcqwkAE6RecordILi439EE_param_0];
ld.param.u64 	%rd4, [_ZN8__main__11complicatedB2v1B96cw51cXTLSUwHBinCqbbgUAAGBlq82ILSCEQYkgSQBFCjFSaBZJtttTo4sahbKUBDUB3kNVDaQRKChQ_2bSEFA_2fkGdcqwkAE6RecordILi439EE_param_1];
add.u64 	%rd5, %SP, 0;
add.u64 	%rd1, %SPL, 0;
ld.u8 	%rd6, [%rd4];
ld.u8 	%rd7, [%rd4+1];
bfi.b64 	%rd8, %rd7, %rd6, 8, 8;
ld.u8 	%rd9, [%rd4+2];
ld.u8 	%rd10, [%rd4+3];
bfi.b64 	%rd11, %rd10, %rd9, 8, 8;
bfi.b64 	%rd12, %rd11, %rd8, 16, 16;
ld.u8 	%rd13, [%rd4+4];
ld.u8 	%rd14, [%rd4+5];
bfi.b64 	%rd15, %rd14, %rd13, 8, 8;
ld.u8 	%rd16, [%rd4+6];
ld.u8 	%rd17, [%rd4+7];
bfi.b64 	%rd18, %rd17, %rd16, 8, 8;
bfi.b64 	%rd19, %rd18, %rd15, 16, 16;
bfi.b64 	%rd20, %rd19, %rd12, 32, 32;
mov.b64 	%fd1, %rd20;
add.f64 	%fd2, %fd1, 0d3FF0000000000000;
mov.b64 	%rd21, %fd2;
st.u8 	[%rd4], %rd21;
shr.u64 	%rd22, %rd21, 56;
st.u8 	[%rd4+7], %rd22;
shr.u64 	%rd23, %rd21, 48;
st.u8 	[%rd4+6], %rd23;
shr.u64 	%rd24, %rd21, 40;
st.u8 	[%rd4+5], %rd24;
shr.u64 	%rd25, %rd21, 32;
st.u8 	[%rd4+4], %rd25;
shr.u64 	%rd26, %rd21, 24;
st.u8 	[%rd4+3], %rd26;
shr.u64 	%rd27, %rd21, 16;
st.u8 	[%rd4+2], %rd27;
shr.u64 	%rd28, %rd21, 8;
st.u8 	[%rd4+1], %rd28;
ld.u8 	%rd29, [%rd4+8];
ld.u8 	%rd30, [%rd4+9];
bfi.b64 	%rd31, %rd30, %rd29, 8, 8;
ld.u8 	%rd32, [%rd4+10];
ld.u8 	%rd33, [%rd4+11];
bfi.b64 	%rd34, %rd33, %rd32, 8, 8;
bfi.b64 	%rd35, %rd34, %rd31, 16, 16;
ld.u8 	%rd36, [%rd4+12];
ld.u8 	%rd37, [%rd4+13];
bfi.b64 	%rd38, %rd37, %rd36, 8, 8;
ld.u8 	%rd39, [%rd4+14];
ld.u8 	%rd40, [%rd4+15];
bfi.b64 	%rd41, %rd40, %rd39, 8, 8;
bfi.b64 	%rd42, %rd41, %rd38, 16, 16;
bfi.b64 	%rd43, %rd42, %rd35, 32, 32;
mov.b64 	%fd3, %rd43;
add.f64 	%fd4, %fd3, 0d3FF0000000000000;
mov.b64 	%rd44, %fd4;
st.u8 	[%rd4+8], %rd44;
shr.u64 	%rd45, %rd44, 56;
st.u8 	[%rd4+15], %rd45;
shr.u64 	%rd46, %rd44, 48;
st.u8 	[%rd4+14], %rd46;
shr.u64 	%rd47, %rd44, 40;
st.u8 	[%rd4+13], %rd47;
shr.u64 	%rd48, %rd44, 32;
st.u8 	[%rd4+12], %rd48;
shr.u64 	%rd49, %rd44, 24;
st.u8 	[%rd4+11], %rd49;
shr.u64 	%rd50, %rd44, 16;
st.u8 	[%rd4+10], %rd50;
shr.u64 	%rd51, %rd44, 8;
st.u8 	[%rd4+9], %rd51;
ld.u8 	%rd52, [%rd4+16];
ld.u8 	%rd53, [%rd4+17];
bfi.b64 	%rd54, %rd53, %rd52, 8, 8;
ld.u8 	%rd55, [%rd4+18];
ld.u8 	%rd56, [%rd4+19];
bfi.b64 	%rd57, %rd56, %rd55, 8, 8;
bfi.b64 	%rd58, %rd57, %rd54, 16, 16;
ld.u8 	%rd59, [%rd4+20];
ld.u8 	%rd60, [%rd4+21];
bfi.b64 	%rd61, %rd60, %rd59, 8, 8;
ld.u8 	%rd62, [%rd4+22];
ld.u8 	%rd63, [%rd4+23];
bfi.b64 	%rd64, %rd63, %rd62, 8, 8;
bfi.b64 	%rd65, %rd64, %rd61, 16, 16;
bfi.b64 	%rd66, %rd65, %rd58, 32, 32;
mov.b64 	%fd5, %rd66;
add.f64 	%fd6, %fd5, 0d3FF0000000000000;
mov.b64 	%rd67, %fd6;
st.u8 	[%rd4+16], %rd67;
shr.u64 	%rd68, %rd67, 56;
st.u8 	[%rd4+23], %rd68;
shr.u64 	%rd69, %rd67, 48;
st.u8 	[%rd4+22], %rd69;
shr.u64 	%rd70, %rd67, 40;
st.u8 	[%rd4+21], %rd70;
shr.u64 	%rd71, %rd67, 32;
st.u8 	[%rd4+20], %rd71;
shr.u64 	%rd72, %rd67, 24;
st.u8 	[%rd4+19], %rd72;
shr.u64 	%rd73, %rd67, 16;
st.u8 	[%rd4+18], %rd73;
shr.u64 	%rd74, %rd67, 8;
st.u8 	[%rd4+17], %rd74;
cvt.rn.f32.f64 	%f1, %fd2;
mov.u32 	%r2, 0;
st.local.u32 	[%rd1], %r2;
{ // callseq 0, 0
.reg .b32 temp_param_reg;
.param .b64 param0;
st.param.b64 	[param0+0], %rd5;
.param .b32 param1;
st.param.f32 	[param1+0], %f1;
.param .b32 retval0;
call.uni (retval0), 
dummy, 
(
param0, 
param1
);
ld.param.b32 	%r1, [retval0+0];
} // callseq 0
setp.eq.s32 	%p1, %r1, 0;
@%p1 bra 	$L__BB0_2;
setp.ne.s32 	%p2, %r1, -2;
@%p2 bra 	$L__BB0_3;
$L__BB0_2:
ld.local.s32 	%rd75, [%rd1];
ld.u8 	%rd76, [%rd4+24];
ld.u8 	%rd77, [%rd4+25];
bfi.b64 	%rd78, %rd77, %rd76, 8, 8;
ld.u8 	%rd79, [%rd4+26];
ld.u8 	%rd80, [%rd4+27];
bfi.b64 	%rd81, %rd80, %rd79, 8, 8;
bfi.b64 	%rd82, %rd81, %rd78, 16, 16;
ld.u8 	%rd83, [%rd4+28];
ld.u8 	%rd84, [%rd4+29];
bfi.b64 	%rd85, %rd84, %rd83, 8, 8;
ld.u8 	%rd86, [%rd4+30];
ld.u8 	%rd87, [%rd4+31];
bfi.b64 	%rd88, %rd87, %rd86, 8, 8;
bfi.b64 	%rd89, %rd88, %rd85, 16, 16;
bfi.b64 	%rd90, %rd89, %rd82, 32, 32;
add.s64 	%rd91, %rd90, 1;
st.u8 	[%rd4+24], %rd91;
shr.u64 	%rd92, %rd91, 56;
st.u8 	[%rd4+31], %rd92;
shr.u64 	%rd93, %rd91, 48;
st.u8 	[%rd4+30], %rd93;
shr.u64 	%rd94, %rd91, 40;
st.u8 	[%rd4+29], %rd94;
shr.u64 	%rd95, %rd91, 32;
st.u8 	[%rd4+28], %rd95;
shr.u64 	%rd96, %rd91, 24;
st.u8 	[%rd4+27], %rd96;
shr.u64 	%rd97, %rd91, 16;
st.u8 	[%rd4+26], %rd97;
shr.u64 	%rd98, %rd91, 8;
st.u8 	[%rd4+25], %rd98;
add.s64 	%rd99, %rd75, 1;
st.u8 	[%rd4+32], %rd99;
shr.u64 	%rd100, %rd99, 56;
st.u8 	[%rd4+39], %rd100;
shr.u64 	%rd101, %rd99, 48;
st.u8 	[%rd4+38], %rd101;
shr.u64 	%rd102, %rd99, 40;
st.u8 	[%rd4+37], %rd102;
shr.u64 	%rd103, %rd99, 32;
st.u8 	[%rd4+36], %rd103;
shr.u64 	%rd104, %rd99, 24;
st.u8 	[%rd4+35], %rd104;
shr.u64 	%rd105, %rd99, 16;
st.u8 	[%rd4+34], %rd105;
shr.u64 	%rd106, %rd99, 8;
st.u8 	[%rd4+33], %rd106;
ld.u8 	%rs1, [%rd4+40];
setp.eq.s16 	%p3, %rs1, 0;
selp.u16 	%rs2, 1, 0, %p3;
st.u8 	[%rd4+40], %rs2;
st.u64 	[%rd3], %rd4;
st.param.b32 	[func_retval0+0], %r2;
ret;
$L__BB0_3:
st.param.b32 	[func_retval0+0], %r1;
ret;
}
