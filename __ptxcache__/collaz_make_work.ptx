.version	7.3	.target	sm_86	.address_size	64	.extern	.func(.param	.b32	func_retval0)collaz_hrm_even_async(.param	.b64	collaz_hrm_even_async_param_0,	.param	.b64	collaz_hrm_even_async_param_1,	.param	.b64	collaz_hrm_even_async_param_2);
.extern	.func(.param	.b32	func_retval0)collaz_hrm_odd_async(.param	.b64	collaz_hrm_odd_async_param_0,	.param	.b64	collaz_hrm_odd_async_param_1,	.param	.b64	collaz_hrm_odd_async_param_2);
.common	.global	.align	8	.u64	_ZN08NumbaEnv8__main__9make_workB2v3B96cw51cXTLSUwHBinCqbbgUAAGBlq82ILSCEQYkgSQBFCjFSaBZJtttTo4sahbKUBDUB3kNVDaQRKChQ_2bSEFA_2fkGdcqwkAE6RecordILi440EE;
 .visible	.func(.param	.b32	func_retval0)_make_work(.param	.b64	_ZN8__main__9make_workB2v3B96cw51cXTLSUwHBinCqbbgUAAGBlq82ILSCEQYkgSQBFCjFSaBZJtttTo4sahbKUBDUB3kNVDaQRKChQ_2bSEFA_2fkGdcqwkAE6RecordILi440EE_param_0,	.param	.b64	_ZN8__main__9make_workB2v3B96cw51cXTLSUwHBinCqbbgUAAGBlq82ILSCEQYkgSQBFCjFSaBZJtttTo4sahbKUBDUB3kNVDaQRKChQ_2bSEFA_2fkGdcqwkAE6RecordILi440EE_param_1){
	.local	.align	8	.b8	__local_depot0[32];
	.reg	.b64	%SP;
	.reg	.b64	%SPL;
	.reg	.pred	%p<8>;
	.reg	.b16	%rs<4>;
	.reg	.b32	%r<8>;
	.reg	.b64	%rd<26>;
	mov.u64	%SPL,	__local_depot0;
	cvta.local.u64	%SP,	%SPL;
	ld.param.u64	%rd5,	[_ZN8__main__9make_workB2v3B96cw51cXTLSUwHBinCqbbgUAAGBlq82ILSCEQYkgSQBFCjFSaBZJtttTo4sahbKUBDUB3kNVDaQRKChQ_2bSEFA_2fkGdcqwkAE6RecordILi440EE_param_0];
	ld.param.u64	%rd6,	[_ZN8__main__9make_workB2v3B96cw51cXTLSUwHBinCqbbgUAAGBlq82ILSCEQYkgSQBFCjFSaBZJtttTo4sahbKUBDUB3kNVDaQRKChQ_2bSEFA_2fkGdcqwkAE6RecordILi440EE_param_1];
	add.u64	%rd7,	%SP,	0;
	add.u64	%rd8,	%SPL,	0;
	mov.u64	%rd9,	0;
	mov.u16	%rs1,	0;
	st.local.v4.u8[%rd8],	{%rs1,	%rs1,	%rs1,	%rs1};
	
	add.s64	%rd1,	%rd8,	4;
	st.local.v4.u8[%rd8+4],	{%rs1,	%rs1,	%rs1,	%rs1};
	
	st.local.v4.u8[%rd8+8],	{%rs1,	%rs1,	%rs1,	%rs1};
	
	add.u64	%rd10,	%SP,	16;
	add.u64	%rd2,	%SPL,	16;
	st.local.u64[%rd2],	%rd9;
	add.u64	%rd11,	%SP,	24;
	add.u64	%rd3,	%SPL,	24;
	st.local.u64[%rd3],	%rd9;
	atom.add.u64	%rd4,	[%rd6],	1;
	setp.gt.u64	%p1,	%rd4,	9;
	@%p1	bra	$L__BB0_8;
	bra.uni	$L__BB0_1;
	$L__BB0_8:
	st.u8[%rd5],	%rs1;
	mov.u32	%r6,	0;
	st.param.b32[func_retval0+0],	%r6;
	ret;
	$L__BB0_1:
	cvt.u32.u64	%r4,	%rd4;
	st.local.u32[%rd8],	%r4;
	st.local.u32[%rd1],	%r4;
	shr.u64	%rd14,	%rd4,	63;
	add.s64	%rd15,	%rd4,	%rd14;
	and.b64	%rd16,	%rd15,	-2;
	sub.s64	%rd17,	%rd4,	%rd16;
	setp.lt.s64	%p2,	%rd17,	0;
	add.s64	%rd18,	%rd17,	2;
	selp.b64	%rd19,	%rd18,	%rd17,	%p2;
	setp.eq.s64	%p3,	%rd19,	0;
	@%p3	bra	$L__BB0_5;
	st.local.u64[%rd3],	%rd9;
	
	{
		.reg	.b32	temp_param_reg;
		.param	.b64	param0;
		st.param.b64[param0+0],	%rd11;
		.param	.b64	param1;
		st.param.b64[param1+0],	%rd6;
		.param	.b64	param2;
		st.param.b64[param2+0],	%rd7;
		.param	.b32	retval0;
		call(retval0),	collaz_hrm_odd_async,	(param0,	param1,	param2);
		ld.param.b32	%r7,	[retval0+0];
		
	}
	setp.eq.s32	%p4,	%r7,	-2;
	@%p4	bra	$L__BB0_7;
	setp.eq.s32	%p5,	%r7,	0;
	@%p5	bra	$L__BB0_7;
	bra.uni	$L__BB0_4;
	$L__BB0_5:
	st.local.u64[%rd2],	%rd9;
	
	{
		.reg	.b32	temp_param_reg;
		.param	.b64	param0;
		st.param.b64[param0+0],	%rd10;
		.param	.b64	param1;
		st.param.b64[param1+0],	%rd6;
		.param	.b64	param2;
		st.param.b64[param2+0],	%rd7;
		.param	.b32	retval0;
		call(retval0),	collaz_hrm_even_async,	(param0,	param1,	param2);
		ld.param.b32	%r7,	[retval0+0];
		
	}
	setp.eq.s32	%p6,	%r7,	0;
	@%p6	bra	$L__BB0_7;
	setp.ne.s32	%p7,	%r7,	-2;
	@%p7	bra	$L__BB0_4;
	$L__BB0_7:
	mov.u16	%rs2,	1;
	st.u8[%rd5],	%rs2;
	mov.u32	%r5,	0;
	st.param.b32[func_retval0+0],	%r5;
	ret;
	$L__BB0_4:
	st.param.b32[func_retval0+0],	%r7;
	ret;
	
}

