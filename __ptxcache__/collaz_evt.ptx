//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-32688072
// Cuda compilation tools, release 12.1, V12.1.105
// Based on NVVM 7.0.1
//

.version 8.1
.target sm_86
.address_size 64

	// .globl	init_program
.extern .func  (.param .b32 func_retval0) vprintf
(
	.param .b64 vprintf_param_0,
	.param .b64 vprintf_param_1
)
;
.extern .func  (.param .b32 func_retval0) _odd
(
	.param .b64 _odd_param_0,
	.param .b64 _odd_param_1,
	.param .b64 _odd_param_2
)
;
.extern .func  (.param .b32 func_retval0) _even
(
	.param .b64 _even_param_0,
	.param .b64 _even_param_1,
	.param .b64 _even_param_2
)
;
.extern .func  (.param .b32 func_retval0) _initialize
(
	.param .b64 _initialize_param_0,
	.param .b64 _initialize_param_1
)
;
.extern .func  (.param .b32 func_retval0) _make_work
(
	.param .b64 _make_work_param_0,
	.param .b64 _make_work_param_1
)
;
.extern .func  (.param .b32 func_retval0) _finalize
(
	.param .b64 _finalize_param_0,
	.param .b64 _finalize_param_1
)
;
.weak .shared .align 1 .b8 _ZZ15_inner_dev_initI12EventProgramI6collazEEvRNT_13DeviceContextERNS3_11DeviceStateEE8_grp_ctx[1];
.weak .shared .align 8 .u64 _ZZ15_inner_dev_initI12EventProgramI6collazEEvRNT_13DeviceContextERNS3_11DeviceStateEE5group;
.weak .shared .align 8 .b8 _ZZN12EventProgramI6collazE4execEjE10group_work[16];
.weak .shared .align 1 .u8 _ZZN12EventProgramI6collazE4execEjE4done;
.weak .shared .align 4 .u32 _ZZN12EventProgramI6collazE4execEjE7func_id;
.weak .shared .align 1 .b8 _ZZ15_inner_dev_execI12EventProgramI6collazEEvRNT_13DeviceContextERNS3_11DeviceStateEmE8_grp_ctx[1];
.weak .shared .align 8 .u64 _ZZ15_inner_dev_execI12EventProgramI6collazEEvRNT_13DeviceContextERNS3_11DeviceStateEmE5group;
.global .align 1 .b8 $str[8] = {40, 99, 116, 120, 37, 112, 41, 0};
.global .align 1 .b8 $str$1[8] = {40, 115, 116, 97, 37, 112, 41, 0};
.global .align 1 .b8 $str$2[8] = {40, 112, 114, 101, 37, 112, 41, 0};
.global .align 1 .b8 $str$3[8] = {40, 103, 116, 120, 37, 112, 41, 0};

.visible .func  (.param .b32 func_retval0) init_program(
	.param .b64 init_program_param_0,
	.param .b64 init_program_param_1,
	.param .b64 init_program_param_2
)
{
	.reg .b32 	%r<2>;


	mov.u32 	%r1, 0;
	st.param.b32 	[func_retval0+0], %r1;
	ret;

}
	// .globl	exec_program
.visible .func  (.param .b32 func_retval0) exec_program(
	.param .b64 exec_program_param_0,
	.param .b64 exec_program_param_1,
	.param .b64 exec_program_param_2,
	.param .b64 exec_program_param_3
)
{
	.local .align 8 .b8 	__local_depot1[104];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<24>;
	.reg .b16 	%rs<10>;
	.reg .b32 	%r<99>;
	.reg .b64 	%rd<114>;


	mov.u64 	%SPL, __local_depot1;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd32, [exec_program_param_1];
	ld.param.u64 	%rd34, [exec_program_param_2];
	ld.param.u64 	%rd33, [exec_program_param_3];
	add.u64 	%rd35, %SP, 0;
	add.u64 	%rd36, %SPL, 0;
	add.u64 	%rd37, %SP, 48;
	add.u64 	%rd38, %SPL, 48;
	add.u64 	%rd39, %SP, 68;
	add.u64 	%rd40, %SPL, 68;
	add.u64 	%rd41, %SP, 80;
	add.u64 	%rd42, %SPL, 80;
	add.u64 	%rd43, %SP, 88;
	add.u64 	%rd44, %SPL, 88;
	st.local.u64 	[%rd44], %rd34;
	st.local.u64 	[%rd42], %rd32;
	mov.u64 	%rd45, $str;
	cvta.global.u64 	%rd46, %rd45;
	mov.u32 	%r90, 0;
	{ // callseq 0, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd46;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd41;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r29, [retval0+0];
	} // callseq 0
	st.local.u64 	[%rd42], %rd43;
	mov.u64 	%rd47, $str$1;
	cvta.global.u64 	%rd48, %rd47;
	{ // callseq 1, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd48;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd41;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r30, [retval0+0];
	} // callseq 1
	ld.local.u64 	%rd49, [%rd44+-8];
	st.local.u64 	[%rd42], %rd49;
	mov.u64 	%rd50, $str$2;
	cvta.global.u64 	%rd51, %rd50;
	{ // callseq 2, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd51;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd41;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r31, [retval0+0];
	} // callseq 2
	mov.u32 	%r32, _ZZ15_inner_dev_execI12EventProgramI6collazEEvRNT_13DeviceContextERNS3_11DeviceStateEmE8_grp_ctx;
	{ .reg .b64 %tmp;
	  cvt.u64.u32 	%tmp, %r32;
	  cvta.shared.u64 	%rd52, %tmp; }
	st.local.u64 	[%rd42], %rd52;
	mov.u64 	%rd53, $str$3;
	cvta.global.u64 	%rd54, %rd53;
	{ // callseq 3, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd54;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd41;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r33, [retval0+0];
	} // callseq 3
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r34, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	mad.lo.s32 	%r35, %r34, %r1, %r2;
	st.local.u32 	[%rd40], %r35;
	st.local.u32 	[%rd40+4], %r35;
	st.local.u64 	[%rd36], %rd32;
	st.local.u64 	[%rd36+8], %rd52;
	st.local.u64 	[%rd36+16], %rd39;
	st.local.u64 	[%rd36+24], %rd43;
	mov.u32 	%r36, _ZZ15_inner_dev_execI12EventProgramI6collazEEvRNT_13DeviceContextERNS3_11DeviceStateEmE5group;
	{ .reg .b64 %tmp;
	  cvt.u64.u32 	%tmp, %r36;
	  cvta.shared.u64 	%rd55, %tmp; }
	st.local.u64 	[%rd36+32], %rd55;
	add.u64 	%rd56, %SP, 96;
	st.local.u64 	[%rd36+40], %rd56;
	st.local.u32 	[%rd38], %r90;
	{ // callseq 4, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd37;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd35;
	.param .b32 retval0;
	call.uni (retval0), 
	_initialize, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r37, [retval0+0];
	} // callseq 4
	bar.sync 	0;
	// begin inline asm
	activemask.b32 %r26;
	// end inline asm
	bar.sync 	0;
	bar.sync 	0;
	// begin inline asm
	activemask.b32 %r27;
	// end inline asm
	brev.b32 	%r38, %r27;
	bfind.shiftamt.u32 	%r39, %r38;
	setp.ne.s32 	%p3, %r39, %r2;
	@%p3 bra 	$L__BB1_2;

	mov.u64 	%rd57, 0;
	st.shared.u64 	[_ZZN12EventProgramI6collazE4execEjE10group_work], %rd57;
	mov.u32 	%r40, 0;
	st.shared.v2.u32 	[_ZZN12EventProgramI6collazE4execEjE10group_work+8], {%r40, %r40};

$L__BB1_2:
	cvt.u32.u64 	%r42, %rd33;
	bar.sync 	0;
	shl.b32 	%r3, %r42, 5;
	mul.lo.s32 	%r4, %r1, %r42;
	add.u64 	%rd63, %SP, 64;
	add.u64 	%rd5, %SPL, 64;

$L__BB1_3:
	bar.sync 	0;
	// begin inline asm
	activemask.b32 %r43;
	// end inline asm
	brev.b32 	%r44, %r43;
	bfind.shiftamt.u32 	%r45, %r44;
	setp.ne.s32 	%p4, %r45, %r2;
	@%p4 bra 	$L__BB1_12;

	mov.u32 	%r93, 0;
	mov.u16 	%rs1, 1;
	st.shared.u8 	[_ZZN12EventProgramI6collazE4execEjE4done], %rs1;
	ld.u64 	%rd108, [%rd32+8];
	add.s64 	%rd107, %rd108, 28;
	ld.u32 	%r94, [%rd108+32];
	ld.u32 	%r91, [%rd108+28];
	setp.lt.u32 	%p5, %r91, %r94;
	@%p5 bra 	$L__BB1_6;

	ld.u64 	%rd108, [%rd32+16];
	add.s64 	%rd107, %rd108, 28;
	ld.u32 	%r94, [%rd108+32];
	ld.u32 	%r91, [%rd108+28];
	setp.ge.u32 	%p6, %r91, %r94;
	mov.u32 	%r93, 1;
	@%p6 bra 	$L__BB1_12;

$L__BB1_6:
	mov.u16 	%rs2, 0;
	st.shared.u8 	[_ZZN12EventProgramI6collazE4execEjE4done], %rs2;
	st.shared.u32 	[_ZZN12EventProgramI6collazE4execEjE7func_id], %r93;
	setp.gt.u32 	%p7, %r91, %r94;
	mov.u32 	%r95, %r94;
	@%p7 bra 	$L__BB1_8;

	atom.add.u32 	%r48, [%rd107], %r3;
	add.s32 	%r49, %r48, %r3;
	min.u32 	%r13, %r48, %r94;
	min.u32 	%r95, %r49, %r94;
	mov.u32 	%r94, %r13;

$L__BB1_8:
	ld.u8 	%rs3, [%rd108];
	setp.eq.s16 	%p8, %rs3, 0;
	@%p8 bra 	$L__BB1_10;

	ld.u64 	%rd109, [%rd108+16];
	bra.uni 	$L__BB1_11;

$L__BB1_10:
	ld.u64 	%rd109, [%rd108+8];

$L__BB1_11:
	st.shared.u64 	[_ZZN12EventProgramI6collazE4execEjE10group_work], %rd109;
	st.shared.v2.u32 	[_ZZN12EventProgramI6collazE4execEjE10group_work+8], {%r94, %r95};

$L__BB1_12:
	bar.sync 	0;
	ld.shared.u8 	%rs4, [_ZZN12EventProgramI6collazE4execEjE4done];
	setp.eq.s16 	%p9, %rs4, 0;
	@%p9 bra 	$L__BB1_15;
	bra.uni 	$L__BB1_14;

$L__BB1_15:
	ld.shared.u64 	%rd25, [_ZZN12EventProgramI6collazE4execEjE10group_work];
	mov.u32 	%r98, 0;
	ld.shared.v2.u32 	{%r55, %r56}, [_ZZN12EventProgramI6collazE4execEjE10group_work+8];
	setp.ge.u32 	%p11, %r55, %r56;
	mov.u32 	%r97, %r98;
	@%p11 bra 	$L__BB1_20;

	bar.sync 	0;
	// begin inline asm
	activemask.b32 %r57;
	// end inline asm
	brev.b32 	%r58, %r57;
	bfind.shiftamt.u32 	%r59, %r58;
	setp.ne.s32 	%p12, %r59, %r2;
	@%p12 bra 	$L__BB1_18;

	ld.shared.u32 	%r60, [_ZZN12EventProgramI6collazE4execEjE10group_work+8];
	add.s32 	%r61, %r60, %r4;
	st.shared.u32 	[_ZZN12EventProgramI6collazE4execEjE10group_work+8], %r61;

$L__BB1_18:
	add.s32 	%r62, %r55, %r2;
	add.s32 	%r63, %r62, %r4;
	bar.sync 	0;
	min.u32 	%r97, %r63, %r56;
	min.u32 	%r98, %r62, %r56;
	bra.uni 	$L__BB1_20;

$L__BB1_25:
	st.local.u64 	[%rd36], %rd32;
	st.local.u64 	[%rd36+8], %rd52;
	st.local.u64 	[%rd36+16], %rd39;
	st.local.u64 	[%rd36+24], %rd43;
	st.local.u64 	[%rd36+32], %rd55;
	st.local.u64 	[%rd36+40], %rd56;
	st.local.u64 	[%rd38], %rd111;
	st.local.u64 	[%rd38+8], %rd110;
	mov.u32 	%r68, 0;
	st.local.u32 	[%rd5], %r68;
	{ // callseq 6, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd63;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd35;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd37;
	.param .b32 retval0;
	call.uni (retval0), 
	_even, 
	(
	param0, 
	param1, 
	param2
	);
	ld.param.b32 	%r69, [retval0+0];
	} // callseq 6

$L__BB1_20:
	setp.lt.u32 	%p1, %r98, %r97;
	setp.ge.u32 	%p14, %r98, %r97;
	mov.pred 	%p23, -1;
	@%p14 bra 	$L__BB1_22;

	mul.wide.u32 	%rd76, %r98, 32;
	add.s64 	%rd77, %rd25, %rd76;
	ld.u64 	%rd111, [%rd77+8];
	ld.u64 	%rd110, [%rd77+16];
	mov.pred 	%p23, 0;

$L__BB1_22:
	selp.b32 	%r64, %r1, 0, %p1;
	add.s32 	%r98, %r64, %r98;
	@%p23 bra 	$L__BB1_27;

	ld.shared.u32 	%r65, [_ZZN12EventProgramI6collazE4execEjE7func_id];
	setp.eq.s32 	%p16, %r65, 0;
	@%p16 bra 	$L__BB1_26;

	setp.ne.s32 	%p17, %r65, 1;
	@%p17 bra 	$L__BB1_20;
	bra.uni 	$L__BB1_25;

$L__BB1_26:
	st.local.u64 	[%rd36], %rd32;
	st.local.u64 	[%rd36+8], %rd52;
	st.local.u64 	[%rd36+16], %rd39;
	st.local.u64 	[%rd36+24], %rd43;
	st.local.u64 	[%rd36+32], %rd55;
	st.local.u64 	[%rd36+40], %rd56;
	st.local.u64 	[%rd38], %rd111;
	st.local.u64 	[%rd38+8], %rd110;
	mov.u32 	%r72, 0;
	st.local.u32 	[%rd5], %r72;
	{ // callseq 7, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd63;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd35;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd37;
	.param .b32 retval0;
	call.uni (retval0), 
	_odd, 
	(
	param0, 
	param1, 
	param2
	);
	ld.param.b32 	%r73, [retval0+0];
	} // callseq 7
	bra.uni 	$L__BB1_20;

$L__BB1_27:
	setp.lt.u32 	%p18, %r90, 1048575;
	add.s32 	%r90, %r90, 1;
	@%p18 bra 	$L__BB1_3;
	bra.uni 	$L__BB1_28;

$L__BB1_14:
	st.local.u64 	[%rd36], %rd32;
	st.local.u64 	[%rd36+8], %rd52;
	st.local.u64 	[%rd36+16], %rd39;
	st.local.u64 	[%rd36+24], %rd43;
	st.local.u64 	[%rd36+32], %rd55;
	st.local.u64 	[%rd36+40], %rd56;
	{ // callseq 5, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd37;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd35;
	.param .b32 retval0;
	call.uni (retval0), 
	_make_work, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r52, [retval0+0];
	} // callseq 5
	ld.local.u8 	%rs5, [%rd38];
	setp.eq.s16 	%p10, %rs5, 0;
	@%p10 bra 	$L__BB1_28;
	bra.uni 	$L__BB1_14;

$L__BB1_28:
	bar.sync 	0;
	st.local.u64 	[%rd36], %rd32;
	st.local.u64 	[%rd36+8], %rd52;
	st.local.u64 	[%rd36+16], %rd39;
	st.local.u64 	[%rd36+24], %rd43;
	st.local.u64 	[%rd36+32], %rd55;
	st.local.u64 	[%rd36+40], %rd56;
	mov.u32 	%r76, 0;
	st.local.u32 	[%rd38], %r76;
	{ // callseq 8, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd37;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd35;
	.param .b32 retval0;
	call.uni (retval0), 
	_finalize, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r77, [retval0+0];
	} // callseq 8
	membar.gl;
	bar.sync 	0;
	setp.ne.s32 	%p19, %r2, 0;
	@%p19 bra 	$L__BB1_31;

	ld.u64 	%rd101, [%rd32];
	atom.add.u32 	%r78, [%rd101], 1;
	mov.u32 	%r79, %nctaid.x;
	add.s32 	%r80, %r79, -1;
	setp.ne.s32 	%p20, %r78, %r80;
	@%p20 bra 	$L__BB1_31;

	ld.u64 	%rd102, [%rd32];
	mov.u32 	%r81, 0;
	atom.exch.b32 	%r82, [%rd102], 0;
	ld.u64 	%rd103, [%rd32+8];
	ld.u8 	%rs6, [%rd103];
	setp.eq.s16 	%p21, %rs6, 0;
	selp.u16 	%rs7, 1, 0, %p21;
	st.u8 	[%rd103], %rs7;
	ld.u32 	%r83, [%rd103+24];
	ld.u32 	%r84, [%rd103+36];
	min.u32 	%r85, %r84, %r83;
	st.u32 	[%rd103+28], %r81;
	st.u32 	[%rd103+32], %r85;
	st.u32 	[%rd103+36], %r81;
	st.u32 	[%rd103+40], %r83;
	ld.u64 	%rd104, [%rd32+16];
	ld.u8 	%rs8, [%rd104];
	setp.eq.s16 	%p22, %rs8, 0;
	selp.u16 	%rs9, 1, 0, %p22;
	st.u8 	[%rd104], %rs9;
	ld.u32 	%r86, [%rd104+24];
	ld.u32 	%r87, [%rd104+36];
	min.u32 	%r88, %r87, %r86;
	st.u32 	[%rd104+28], %r81;
	st.u32 	[%rd104+32], %r88;
	st.u32 	[%rd104+36], %r81;
	st.u32 	[%rd104+40], %r86;

$L__BB1_31:
	st.param.b32 	[func_retval0+0], %r76;
	ret;

}
	// .globl	dispatch_odd_async
.visible .func  (.param .b32 func_retval0) dispatch_odd_async(
	.param .b64 dispatch_odd_async_param_0,
	.param .b64 dispatch_odd_async_param_1,
	.param .b64 dispatch_odd_async_param_2
)
{
	.reg .pred 	%p<8>;
	.reg .b16 	%rs<2>;
	.reg .b32 	%r<6>;
	.reg .b64 	%rd<20>;


	ld.param.u64 	%rd3, [dispatch_odd_async_param_1];
	ld.param.u64 	%rd12, [dispatch_odd_async_param_2];
	ld.u64 	%rd1, [%rd12];
	mov.u64 	%rd18, 0;
	ld.u64 	%rd2, [%rd12+8];
	ld.u64 	%rd13, [%rd3];
	ld.u64 	%rd4, [%rd13+8];
	ld.u32 	%r1, [%rd4+40];
	ld.u32 	%r2, [%rd4+36];
	setp.ge.u32 	%p4, %r2, %r1;
	mov.pred 	%p7, -1;
	@%p4 bra 	$L__BB2_2;

	add.s64 	%rd14, %rd4, 36;
	atom.add.u32 	%r3, [%rd14], 1;
	setp.lt.u32 	%p5, %r3, %r1;
	selp.b32 	%r4, %r3, 0, %p5;
	cvt.u64.u32 	%rd18, %r4;
	setp.ge.u32 	%p7, %r3, %r1;

$L__BB2_2:
	@%p7 bra 	$L__BB2_7;

	ld.u64 	%rd15, [%rd3];
	ld.u64 	%rd7, [%rd15+8];
	ld.u8 	%rs1, [%rd7];
	setp.eq.s16 	%p6, %rs1, 0;
	@%p6 bra 	$L__BB2_5;

	ld.u64 	%rd19, [%rd7+8];
	bra.uni 	$L__BB2_6;

$L__BB2_5:
	ld.u64 	%rd19, [%rd7+16];

$L__BB2_6:
	shl.b64 	%rd16, %rd18, 5;
	add.s64 	%rd17, %rd19, %rd16;
	st.u64 	[%rd17+8], %rd1;
	st.u64 	[%rd17+16], %rd2;

$L__BB2_7:
	mov.u32 	%r5, 0;
	st.param.b32 	[func_retval0+0], %r5;
	ret;

}
	// .globl	dispatch_odd_sync
.visible .func  (.param .b32 func_retval0) dispatch_odd_sync(
	.param .b64 dispatch_odd_sync_param_0,
	.param .b64 dispatch_odd_sync_param_1,
	.param .b64 dispatch_odd_sync_param_2
)
{
	.local .align 8 .b8 	__local_depot3[72];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .b32 	%r<3>;
	.reg .b64 	%rd<17>;


	mov.u64 	%SPL, __local_depot3;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd1, [dispatch_odd_sync_param_1];
	ld.param.u64 	%rd2, [dispatch_odd_sync_param_2];
	add.u64 	%rd3, %SP, 0;
	add.u64 	%rd4, %SPL, 0;
	add.u64 	%rd5, %SP, 48;
	add.u64 	%rd6, %SPL, 48;
	add.u64 	%rd7, %SP, 64;
	add.u64 	%rd8, %SPL, 64;
	ld.u64 	%rd9, [%rd2];
	ld.u64 	%rd10, [%rd2+8];
	ld.u64 	%rd11, [%rd1];
	ld.u64 	%rd12, [%rd1+8];
	ld.u64 	%rd13, [%rd1+16];
	ld.u64 	%rd14, [%rd1+24];
	ld.u64 	%rd15, [%rd1+32];
	ld.u64 	%rd16, [%rd1+40];
	st.local.u64 	[%rd4], %rd11;
	st.local.u64 	[%rd4+8], %rd12;
	st.local.u64 	[%rd4+16], %rd13;
	st.local.u64 	[%rd4+24], %rd14;
	st.local.u64 	[%rd4+32], %rd15;
	st.local.u64 	[%rd4+40], %rd16;
	st.local.u64 	[%rd6], %rd9;
	st.local.u64 	[%rd6+8], %rd10;
	mov.u32 	%r1, 0;
	st.local.u32 	[%rd8], %r1;
	{ // callseq 9, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd7;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd3;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd5;
	.param .b32 retval0;
	call.uni (retval0), 
	_odd, 
	(
	param0, 
	param1, 
	param2
	);
	ld.param.b32 	%r2, [retval0+0];
	} // callseq 9
	st.param.b32 	[func_retval0+0], %r1;
	ret;

}
	// .globl	dispatch_even_async
.visible .func  (.param .b32 func_retval0) dispatch_even_async(
	.param .b64 dispatch_even_async_param_0,
	.param .b64 dispatch_even_async_param_1,
	.param .b64 dispatch_even_async_param_2
)
{
	.reg .pred 	%p<8>;
	.reg .b16 	%rs<2>;
	.reg .b32 	%r<6>;
	.reg .b64 	%rd<20>;


	ld.param.u64 	%rd3, [dispatch_even_async_param_1];
	ld.param.u64 	%rd12, [dispatch_even_async_param_2];
	ld.u64 	%rd1, [%rd12];
	mov.u64 	%rd18, 0;
	ld.u64 	%rd2, [%rd12+8];
	ld.u64 	%rd13, [%rd3];
	ld.u64 	%rd4, [%rd13+16];
	ld.u32 	%r1, [%rd4+40];
	ld.u32 	%r2, [%rd4+36];
	setp.ge.u32 	%p4, %r2, %r1;
	mov.pred 	%p7, -1;
	@%p4 bra 	$L__BB4_2;

	add.s64 	%rd14, %rd4, 36;
	atom.add.u32 	%r3, [%rd14], 1;
	setp.lt.u32 	%p5, %r3, %r1;
	selp.b32 	%r4, %r3, 0, %p5;
	cvt.u64.u32 	%rd18, %r4;
	setp.ge.u32 	%p7, %r3, %r1;

$L__BB4_2:
	@%p7 bra 	$L__BB4_7;

	ld.u64 	%rd15, [%rd3];
	ld.u64 	%rd7, [%rd15+16];
	ld.u8 	%rs1, [%rd7];
	setp.eq.s16 	%p6, %rs1, 0;
	@%p6 bra 	$L__BB4_5;

	ld.u64 	%rd19, [%rd7+8];
	bra.uni 	$L__BB4_6;

$L__BB4_5:
	ld.u64 	%rd19, [%rd7+16];

$L__BB4_6:
	shl.b64 	%rd16, %rd18, 5;
	add.s64 	%rd17, %rd19, %rd16;
	st.u64 	[%rd17+8], %rd1;
	st.u64 	[%rd17+16], %rd2;

$L__BB4_7:
	mov.u32 	%r5, 0;
	st.param.b32 	[func_retval0+0], %r5;
	ret;

}
	// .globl	dispatch_even_sync
.visible .func  (.param .b32 func_retval0) dispatch_even_sync(
	.param .b64 dispatch_even_sync_param_0,
	.param .b64 dispatch_even_sync_param_1,
	.param .b64 dispatch_even_sync_param_2
)
{
	.local .align 8 .b8 	__local_depot5[72];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .b32 	%r<3>;
	.reg .b64 	%rd<17>;


	mov.u64 	%SPL, __local_depot5;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd1, [dispatch_even_sync_param_1];
	ld.param.u64 	%rd2, [dispatch_even_sync_param_2];
	add.u64 	%rd3, %SP, 0;
	add.u64 	%rd4, %SPL, 0;
	add.u64 	%rd5, %SP, 48;
	add.u64 	%rd6, %SPL, 48;
	add.u64 	%rd7, %SP, 64;
	add.u64 	%rd8, %SPL, 64;
	ld.u64 	%rd9, [%rd2];
	ld.u64 	%rd10, [%rd2+8];
	ld.u64 	%rd11, [%rd1];
	ld.u64 	%rd12, [%rd1+8];
	ld.u64 	%rd13, [%rd1+16];
	ld.u64 	%rd14, [%rd1+24];
	ld.u64 	%rd15, [%rd1+32];
	ld.u64 	%rd16, [%rd1+40];
	st.local.u64 	[%rd4], %rd11;
	st.local.u64 	[%rd4+8], %rd12;
	st.local.u64 	[%rd4+16], %rd13;
	st.local.u64 	[%rd4+24], %rd14;
	st.local.u64 	[%rd4+32], %rd15;
	st.local.u64 	[%rd4+40], %rd16;
	st.local.u64 	[%rd6], %rd9;
	st.local.u64 	[%rd6+8], %rd10;
	mov.u32 	%r1, 0;
	st.local.u32 	[%rd8], %r1;
	{ // callseq 10, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd7;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd3;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd5;
	.param .b32 retval0;
	call.uni (retval0), 
	_even, 
	(
	param0, 
	param1, 
	param2
	);
	ld.param.b32 	%r2, [retval0+0];
	} // callseq 10
	st.param.b32 	[func_retval0+0], %r1;
	ret;

}
	// .globl	access_device
.visible .func  (.param .b32 func_retval0) access_device(
	.param .b64 access_device_param_0,
	.param .b64 access_device_param_1
)
{
	.reg .b32 	%r<2>;
	.reg .b64 	%rd<5>;


	ld.param.u64 	%rd1, [access_device_param_0];
	ld.param.u64 	%rd2, [access_device_param_1];
	ld.u64 	%rd3, [%rd2+24];
	ld.u64 	%rd4, [%rd3];
	st.u64 	[%rd1], %rd4;
	mov.u32 	%r1, 0;
	st.param.b32 	[func_retval0+0], %r1;
	ret;

}
	// .globl	access_group
.visible .func  (.param .b32 func_retval0) access_group(
	.param .b64 access_group_param_0,
	.param .b64 access_group_param_1
)
{
	.reg .b32 	%r<2>;
	.reg .b64 	%rd<5>;


	ld.param.u64 	%rd1, [access_group_param_0];
	ld.param.u64 	%rd2, [access_group_param_1];
	ld.u64 	%rd3, [%rd2+32];
	ld.u64 	%rd4, [%rd3];
	st.u64 	[%rd1], %rd4;
	mov.u32 	%r1, 0;
	st.param.b32 	[func_retval0+0], %r1;
	ret;

}
	// .globl	access_thread
.visible .func  (.param .b32 func_retval0) access_thread(
	.param .b64 access_thread_param_0,
	.param .b64 access_thread_param_1
)
{
	.reg .b32 	%r<2>;
	.reg .b64 	%rd<5>;


	ld.param.u64 	%rd1, [access_thread_param_0];
	ld.param.u64 	%rd2, [access_thread_param_1];
	ld.u64 	%rd3, [%rd2+40];
	ld.u64 	%rd4, [%rd3];
	st.u64 	[%rd1], %rd4;
	mov.u32 	%r1, 0;
	st.param.b32 	[func_retval0+0], %r1;
	ret;

}
	// .globl	_ZN4util14current_leaderEv
.visible .func  (.param .b32 func_retval0) _ZN4util14current_leaderEv()
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<6>;


	// begin inline asm
	activemask.b32 %r1;
	// end inline asm
	brev.b32 	%r2, %r1;
	bfind.shiftamt.u32 	%r3, %r2;
	mov.u32 	%r4, %tid.x;
	setp.eq.s32 	%p1, %r3, %r4;
	selp.u32 	%r5, 1, 0, %p1;
	st.param.b32 	[func_retval0+0], %r5;
	ret;

}
	// .globl	_ZN4util13warp_inc_scanEv
.visible .func  (.param .b32 func_retval0) _ZN4util13warp_inc_scanEv()
{
	.reg .b32 	%r<8>;


	// begin inline asm
	activemask.b32 %r1;
	// end inline asm
	mov.u32 	%r2, %tid.x;
	mov.u32 	%r3, -1;
	shl.b32 	%r4, %r3, %r2;
	not.b32 	%r5, %r4;
	and.b32  	%r6, %r1, %r5;
	popc.b32 	%r7, %r6;
	st.param.b32 	[func_retval0+0], %r7;
	ret;

}
	// .globl	_ZN4util12active_countEv
.visible .func  (.param .b32 func_retval0) _ZN4util12active_countEv()
{
	.reg .b32 	%r<3>;


	// begin inline asm
	activemask.b32 %r1;
	// end inline asm
	popc.b32 	%r2, %r1;
	st.param.b32 	[func_retval0+0], %r2;
	ret;

}
	// .globl	_ZN4util9pop_countEj
.visible .func  (.param .b32 func_retval0) _ZN4util9pop_countEj(
	.param .b32 _ZN4util9pop_countEj_param_0
)
{
	.reg .b32 	%r<3>;


	ld.param.u32 	%r1, [_ZN4util9pop_countEj_param_0];
	popc.b32 	%r2, %r1;
	st.param.b32 	[func_retval0+0], %r2;
	ret;

}
	// .globl	_ZN4util9pop_countEy
.visible .func  (.param .b64 func_retval0) _ZN4util9pop_countEy(
	.param .b64 _ZN4util9pop_countEy_param_0
)
{
	.reg .b32 	%r<2>;
	.reg .b64 	%rd<3>;


	ld.param.u64 	%rd1, [_ZN4util9pop_countEy_param_0];
	popc.b64 	%r1, %rd1;
	cvt.u64.u32 	%rd2, %r1;
	st.param.b64 	[func_retval0+0], %rd2;
	ret;

}
	// .globl	_ZN4util13leading_zerosEj
.visible .func  (.param .b32 func_retval0) _ZN4util13leading_zerosEj(
	.param .b32 _ZN4util13leading_zerosEj_param_0
)
{
	.reg .b32 	%r<3>;


	ld.param.u32 	%r1, [_ZN4util13leading_zerosEj_param_0];
	clz.b32 	%r2, %r1;
	st.param.b32 	[func_retval0+0], %r2;
	ret;

}
	// .globl	_ZN4util13leading_zerosEy
.visible .func  (.param .b64 func_retval0) _ZN4util13leading_zerosEy(
	.param .b64 _ZN4util13leading_zerosEy_param_0
)
{
	.reg .b32 	%r<2>;
	.reg .b64 	%rd<3>;


	ld.param.u64 	%rd1, [_ZN4util13leading_zerosEy_param_0];
	clz.b64 	%r1, %rd1;
	cvt.u64.u32 	%rd2, %r1;
	st.param.b64 	[func_retval0+0], %rd2;
	ret;

}
	// .globl	_ZN4util11random_uintERj
.visible .func  (.param .b32 func_retval0) _ZN4util11random_uintERj(
	.param .b64 _ZN4util11random_uintERj_param_0
)
{
	.reg .b32 	%r<3>;
	.reg .b64 	%rd<2>;


	ld.param.u64 	%rd1, [_ZN4util11random_uintERj_param_0];
	ld.u32 	%r1, [%rd1];
	mad.lo.s32 	%r2, %r1, 69069, 1;
	st.u32 	[%rd1], %r2;
	st.param.b32 	[func_retval0+0], %r2;
	ret;

}
	// .globl	_ZN4util11random_uintERy
.visible .func  (.param .b64 func_retval0) _ZN4util11random_uintERy(
	.param .b64 _ZN4util11random_uintERy_param_0
)
{
	.reg .b64 	%rd<5>;


	ld.param.u64 	%rd1, [_ZN4util11random_uintERy_param_0];
	ld.u64 	%rd2, [%rd1];
	mul.lo.s64 	%rd3, %rd2, 2971215073;
	add.s64 	%rd4, %rd3, 12345;
	st.u64 	[%rd1], %rd4;
	st.param.b64 	[func_retval0+0], %rd4;
	ret;

}

