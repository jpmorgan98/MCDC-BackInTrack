//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-26907403
// Cuda compilation tools, release 10.1, V10.1.243
// Based on LLVM 3.4svn
//

.version 6.4
.target sm_70
.address_size 64

	// .globl	init_program
.extern .func  (.param .b32 func_retval0) _initialize
(
	.param .b64 _initialize_param_0,
	.param .b64 _initialize_param_1
)
;
.extern .func  (.param .b32 func_retval0) _make_work
(
	.param .b64 _make_work_param_0,
	.param .b64 _make_work_param_1
)
;
.extern .func  (.param .b32 func_retval0) _iterate
(
	.param .b64 _iterate_param_0,
	.param .b64 _iterate_param_1,
	.param .b64 _iterate_param_2
)
;
.extern .func  (.param .b32 func_retval0) _finalize
(
	.param .b64 _finalize_param_0,
	.param .b64 _finalize_param_1
)
;
.weak .shared .align 1 .b8 _ZZ15_inner_dev_initI12EventProgramI4mcdcEEvRNT_13DeviceContextERNS3_11DeviceStateEE8_grp_ctx[1];
.weak .shared .align 8 .u64 _ZZ15_inner_dev_initI12EventProgramI4mcdcEEvRNT_13DeviceContextERNS3_11DeviceStateEE5group;
.weak .shared .align 8 .b8 _ZZN12EventProgramI4mcdcE4execEjE10group_work[16];
.weak .shared .align 1 .u8 _ZZN12EventProgramI4mcdcE4execEjE4done;
.weak .shared .align 4 .u32 _ZZN12EventProgramI4mcdcE4execEjE7func_id;
.weak .shared .align 1 .u8 _ZZN12EventProgramI4mcdcE4execEjE16should_make_work;
.weak .shared .align 1 .b8 _ZZ15_inner_dev_execI12EventProgramI4mcdcEEvRNT_13DeviceContextERNS3_11DeviceStateEmE8_grp_ctx[1];
.weak .shared .align 8 .u64 _ZZ15_inner_dev_execI12EventProgramI4mcdcEEvRNT_13DeviceContextERNS3_11DeviceStateEmE5group;

.visible .func  (.param .b32 func_retval0) init_program(
	.param .b64 init_program_param_0,
	.param .b64 init_program_param_1,
	.param .b64 init_program_param_2
)
{
	.reg .b32 	%r<2>;


	mov.u32 	%r1, 0;
	st.param.b32	[func_retval0+0], %r1;
	ret;
}

	// .globl	exec_program
.visible .func  (.param .b32 func_retval0) exec_program(
	.param .b64 exec_program_param_0,
	.param .b64 exec_program_param_1,
	.param .b64 exec_program_param_2,
	.param .b64 exec_program_param_3
)
{
	.local .align 8 .b8 	__local_depot1[296];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<26>;
	.reg .b16 	%rs<16>;
	.reg .b32 	%r<111>;
	.reg .b64 	%rd<116>;


	mov.u64 	%SPL, __local_depot1;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd39, [exec_program_param_1];
	ld.param.u64 	%rd41, [exec_program_param_2];
	ld.param.u64 	%rd40, [exec_program_param_3];
	add.u64 	%rd42, %SP, 0;
	add.u64 	%rd43, %SPL, 0;
	add.u64 	%rd44, %SP, 48;
	add.u64 	%rd45, %SPL, 48;
	add.u64 	%rd46, %SP, 268;
	add.u64 	%rd47, %SPL, 268;
	add.u64 	%rd48, %SP, 280;
	add.u64 	%rd49, %SPL, 280;
	st.local.u64 	[%rd49], %rd41;
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r24, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	mad.lo.s32 	%r25, %r1, %r24, %r2;
	st.local.u32 	[%rd47], %r25;
	st.local.u32 	[%rd47+4], %r25;
	st.local.u64 	[%rd43], %rd39;
	mov.u32 	%r26, _ZZ15_inner_dev_execI12EventProgramI4mcdcEEvRNT_13DeviceContextERNS3_11DeviceStateEmE8_grp_ctx;
	{
	.reg .u64 %temp; 
	cvt.u64.u32 	%temp, %r26;
	cvta.shared.u64 	%rd50, %temp;
	}
	st.local.u64 	[%rd43+8], %rd50;
	st.local.u64 	[%rd43+16], %rd46;
	st.local.u64 	[%rd43+24], %rd48;
	mov.u32 	%r27, _ZZ15_inner_dev_execI12EventProgramI4mcdcEEvRNT_13DeviceContextERNS3_11DeviceStateEmE5group;
	{
	.reg .u64 %temp; 
	cvt.u64.u32 	%temp, %r27;
	cvta.shared.u64 	%rd51, %temp;
	}
	st.local.u64 	[%rd43+32], %rd51;
	add.u64 	%rd52, %SP, 288;
	st.local.u64 	[%rd43+40], %rd52;
	mov.u32 	%r104, 0;
	st.local.u32 	[%rd45], %r104;
	// Callseq Start 0
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd44;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd42;
	.param .b32 retval0;
	call.uni (retval0), 
	_initialize, 
	(
	param0, 
	param1
	);
	ld.param.b32	%r29, [retval0+0];
	
	//{
	}// Callseq End 0
	bar.sync 	0;
	// inline asm
	activemask.b32 %r30;
	// inline asm
	bar.sync 	0;
	bar.sync 	0;
	// inline asm
	activemask.b32 %r31;
	// inline asm
	neg.s32 	%r32, %r31;
	and.b32  	%r33, %r31, %r32;
	clz.b32 	%r34, %r33;
	mov.u32 	%r35, 31;
	sub.s32 	%r36, %r35, %r34;
	setp.ne.s32	%p2, %r36, %r2;
	@%p2 bra 	BB1_2;

	mov.u64 	%rd53, 0;
	st.shared.u64 	[_ZZN12EventProgramI4mcdcE4execEjE10group_work], %rd53;
	mov.u32 	%r37, 0;
	st.shared.v2.u32 	[_ZZN12EventProgramI4mcdcE4execEjE10group_work+8], {%r37, %r37};

BB1_2:
	cvt.u32.u64	%r3, %rd40;
	bar.sync 	0;
	shl.b32 	%r4, %r3, 5;
	mul.lo.s32 	%r5, %r1, %r3;
	add.u64 	%rd55, %SP, 264;
	add.u64 	%rd1, %SPL, 264;
	add.u64 	%rd56, %SP, 216;
	add.u64 	%rd2, %SPL, 216;
	add.u64 	%rd57, %SP, 168;
	add.u64 	%rd3, %SPL, 168;
	add.u64 	%rd58, %SP, 160;
	add.u64 	%rd4, %SPL, 160;
	add.u64 	%rd59, %SP, 112;
	add.u64 	%rd5, %SPL, 112;

BB1_3:
	bar.sync 	0;
	// inline asm
	activemask.b32 %r40;
	// inline asm
	neg.s32 	%r41, %r40;
	and.b32  	%r42, %r40, %r41;
	clz.b32 	%r43, %r42;
	sub.s32 	%r45, %r35, %r43;
	setp.ne.s32	%p3, %r45, %r2;
	@%p3 bra 	BB1_11;

	mov.u16 	%rs3, 1;
	st.shared.u8 	[_ZZN12EventProgramI4mcdcE4execEjE4done], %rs3;
	ld.u64 	%rd62, [%rd39+16];
	add.s64 	%rd15, %rd62, 28;
	ld.u32 	%r46, [%rd62+32];
	ld.u32 	%r47, [%rd62+28];
	setp.ge.u32	%p4, %r47, %r46;
	@%p4 bra 	BB1_11;

	mov.u16 	%rs4, 0;
	st.shared.u8 	[_ZZN12EventProgramI4mcdcE4execEjE4done], %rs4;
	mov.u32 	%r48, 0;
	st.shared.u32 	[_ZZN12EventProgramI4mcdcE4execEjE7func_id], %r48;
	ld.u32 	%r49, [%rd15];
	ld.u32 	%r105, [%rd15+4];
	setp.gt.u32	%p5, %r49, %r105;
	mov.u32 	%r106, %r105;
	@%p5 bra 	BB1_7;

	atom.add.u32 	%r50, [%rd15], %r4;
	add.s32 	%r51, %r50, %r4;
	ld.u32 	%r52, [%rd15+4];
	min.u32 	%r105, %r50, %r52;
	min.u32 	%r106, %r51, %r52;

BB1_7:
	ld.u8 	%rs5, [%rd15+-28];
	setp.eq.s16	%p6, %rs5, 0;
	@%p6 bra 	BB1_9;
	bra.uni 	BB1_8;

BB1_9:
	ld.u64 	%rd103, [%rd15+-20];
	bra.uni 	BB1_10;

BB1_8:
	ld.u64 	%rd103, [%rd15+-12];

BB1_10:
	st.shared.u64 	[_ZZN12EventProgramI4mcdcE4execEjE10group_work], %rd103;
	st.shared.v2.u32 	[_ZZN12EventProgramI4mcdcE4execEjE10group_work+8], {%r105, %r106};

BB1_11:
	bar.sync 	0;
	ld.shared.u8 	%rs6, [_ZZN12EventProgramI4mcdcE4execEjE4done];
	setp.eq.s16	%p7, %rs6, 0;
	@%p7 bra 	BB1_21;
	bra.uni 	BB1_12;

BB1_21:
	ld.shared.v2.u32 	{%r72, %r73}, [_ZZN12EventProgramI4mcdcE4execEjE10group_work+8];
	mov.u32 	%r109, 0;
	setp.ge.u32	%p14, %r72, %r73;
	mov.u32 	%r108, %r109;
	@%p14 bra 	BB1_25;

	add.s32 	%r74, %r72, %r2;
	add.s32 	%r75, %r74, %r5;
	min.u32 	%r109, %r74, %r73;
	min.u32 	%r108, %r75, %r73;
	bar.sync 	0;
	// inline asm
	activemask.b32 %r76;
	// inline asm
	neg.s32 	%r77, %r76;
	and.b32  	%r78, %r76, %r77;
	clz.b32 	%r79, %r78;
	sub.s32 	%r81, %r35, %r79;
	setp.ne.s32	%p15, %r81, %r2;
	@%p15 bra 	BB1_24;

	ld.shared.u32 	%r82, [_ZZN12EventProgramI4mcdcE4execEjE10group_work+8];
	add.s32 	%r83, %r82, %r5;
	st.shared.u32 	[_ZZN12EventProgramI4mcdcE4execEjE10group_work+8], %r83;

BB1_24:
	bar.sync 	0;

BB1_25:
	ld.shared.u64 	%rd19, [_ZZN12EventProgramI4mcdcE4execEjE10group_work];
	bra.uni 	BB1_26;

BB1_30:
	st.local.u64 	[%rd3], %rd39;
	st.local.u64 	[%rd3+8], %rd50;
	st.local.u64 	[%rd3+16], %rd46;
	st.local.u64 	[%rd3+24], %rd48;
	st.local.u64 	[%rd3+32], %rd51;
	st.local.u64 	[%rd3+40], %rd52;
	st.local.u64 	[%rd2], %rd109;
	st.local.u64 	[%rd2+8], %rd108;
	st.local.u64 	[%rd2+16], %rd107;
	st.local.u64 	[%rd2+24], %rd106;
	st.local.u64 	[%rd2+32], %rd105;
	st.local.u64 	[%rd2+40], %rd104;
	mov.u32 	%r88, 0;
	st.local.u32 	[%rd1], %r88;
	// Callseq Start 2
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd55;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd57;
	.param .b64 param2;
	st.param.b64	[param2+0], %rd56;
	.param .b32 retval0;
	call.uni (retval0), 
	_iterate, 
	(
	param0, 
	param1, 
	param2
	);
	ld.param.b32	%r89, [retval0+0];
	
	//{
	}// Callseq End 2
	mov.u32 	%r109, %r21;

BB1_26:
	setp.lt.u32	%p17, %r109, %r108;
	selp.b32	%r84, %r1, 0, %p17;
	add.s32 	%r21, %r84, %r109;
	selp.b32	%r103, %r109, %r103, %p17;
	mov.pred 	%p25, -1;
	setp.ge.u32	%p18, %r109, %r108;
	@%p18 bra 	BB1_28;

	mul.wide.u32 	%rd72, %r103, 64;
	add.s64 	%rd73, %rd19, %rd72;
	ld.u64 	%rd109, [%rd73+8];
	ld.u64 	%rd108, [%rd73+16];
	ld.u64 	%rd107, [%rd73+24];
	ld.u64 	%rd106, [%rd73+32];
	ld.u64 	%rd105, [%rd73+40];
	ld.u64 	%rd104, [%rd73+48];
	mov.pred 	%p25, 0;

BB1_28:
	@%p25 bra 	BB1_31;

	ld.shared.u32 	%r85, [_ZZN12EventProgramI4mcdcE4execEjE7func_id];
	setp.ne.s32	%p20, %r85, 0;
	mov.u32 	%r109, %r21;
	@%p20 bra 	BB1_26;
	bra.uni 	BB1_30;

BB1_31:
	setp.lt.u32	%p21, %r104, 1048575;
	add.s32 	%r104, %r104, 1;
	@%p21 bra 	BB1_3;
	bra.uni 	BB1_32;

BB1_12:
	// inline asm
	activemask.b32 %r53;
	// inline asm
	neg.s32 	%r54, %r53;
	and.b32  	%r55, %r53, %r54;
	clz.b32 	%r56, %r55;
	sub.s32 	%r58, %r35, %r56;
	setp.ne.s32	%p8, %r58, %r2;
	@%p8 bra 	BB1_14;

	mov.u16 	%rs7, 1;
	st.shared.u8 	[_ZZN12EventProgramI4mcdcE4execEjE16should_make_work], %rs7;

BB1_14:
	bar.sync 	0;
	ld.shared.u8 	%rs8, [_ZZN12EventProgramI4mcdcE4execEjE16should_make_work];
	setp.eq.s16	%p9, %rs8, 0;
	@%p9 bra 	BB1_32;

BB1_15:
	// inline asm
	activemask.b32 %r59;
	// inline asm
	neg.s32 	%r60, %r59;
	and.b32  	%r61, %r59, %r60;
	clz.b32 	%r62, %r61;
	sub.s32 	%r64, %r35, %r62;
	setp.ne.s32	%p10, %r64, %r2;
	@%p10 bra 	BB1_18;

	ld.u64 	%rd63, [%rd39+16];
	add.s64 	%rd64, %rd63, 36;
	atom.add.u32 	%r65, [%rd64], 0;
	ld.u32 	%r66, [%rd39+8];
	setp.lt.u32	%p11, %r65, %r66;
	@%p11 bra 	BB1_18;

	mov.u16 	%rs9, 0;
	st.shared.u8 	[_ZZN12EventProgramI4mcdcE4execEjE16should_make_work], %rs9;

BB1_18:
	ld.shared.u8 	%rs11, [_ZZN12EventProgramI4mcdcE4execEjE16should_make_work];
	setp.eq.s16	%p12, %rs11, 0;
	mov.u16 	%rs15, 0;
	@%p12 bra 	BB1_20;

	st.local.u64 	[%rd5], %rd39;
	st.local.u64 	[%rd5+8], %rd50;
	st.local.u64 	[%rd5+16], %rd46;
	st.local.u64 	[%rd5+24], %rd48;
	st.local.u64 	[%rd5+32], %rd51;
	st.local.u64 	[%rd5+40], %rd52;
	// Callseq Start 1
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd58;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd59;
	.param .b32 retval0;
	call.uni (retval0), 
	_make_work, 
	(
	param0, 
	param1
	);
	ld.param.b32	%r69, [retval0+0];
	
	//{
	}// Callseq End 1
	ld.local.u8 	%rs15, [%rd4];
	st.shared.u8 	[_ZZN12EventProgramI4mcdcE4execEjE16should_make_work], %rs15;

BB1_20:
	and.b16  	%rs12, %rs15, 255;
	setp.eq.s16	%p13, %rs12, 0;
	@%p13 bra 	BB1_32;
	bra.uni 	BB1_15;

BB1_32:
	bar.sync 	0;
	add.u64 	%rd95, %SPL, 104;
	add.u64 	%rd93, %SPL, 56;
	add.u64 	%rd92, %SP, 56;
	add.u64 	%rd91, %SP, 104;
	st.local.u64 	[%rd93], %rd39;
	st.local.u64 	[%rd93+8], %rd50;
	st.local.u64 	[%rd93+16], %rd46;
	st.local.u64 	[%rd93+24], %rd48;
	st.local.u64 	[%rd93+32], %rd51;
	st.local.u64 	[%rd93+40], %rd52;
	mov.u32 	%r92, 0;
	st.local.u32 	[%rd95], %r92;
	// Callseq Start 3
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd91;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd92;
	.param .b32 retval0;
	call.uni (retval0), 
	_finalize, 
	(
	param0, 
	param1
	);
	ld.param.b32	%r93, [retval0+0];
	
	//{
	}// Callseq End 3
	membar.gl;
	bar.sync 	0;
	setp.ne.s32	%p22, %r2, 0;
	@%p22 bra 	BB1_35;

	ld.u64 	%rd88, [%rd39];
	atom.add.u32 	%r94, [%rd88], 1;
	mov.u32 	%r95, %nctaid.x;
	add.s32 	%r96, %r95, -1;
	setp.ne.s32	%p23, %r94, %r96;
	@%p23 bra 	BB1_35;

	ld.u64 	%rd89, [%rd39];
	atom.exch.b32 	%r97, [%rd89], 0;
	ld.u64 	%rd90, [%rd39+16];
	ld.u8 	%rs13, [%rd90];
	setp.eq.s16	%p24, %rs13, 0;
	selp.u16	%rs14, 1, 0, %p24;
	st.u8 	[%rd90], %rs14;
	ld.u32 	%r98, [%rd90+24];
	ld.u32 	%r99, [%rd90+36];
	st.u32 	[%rd90+28], %r92;
	min.u32 	%r101, %r99, %r98;
	st.v2.u32 	[%rd90+32], {%r101, %r92};
	st.u32 	[%rd90+40], %r98;

BB1_35:
	st.param.b32	[func_retval0+0], %r92;
	ret;
}

	// .globl	dispatch_iterate_async
.visible .func  (.param .b32 func_retval0) dispatch_iterate_async(
	.param .b64 dispatch_iterate_async_param_0,
	.param .b64 dispatch_iterate_async_param_1,
	.param .b64 dispatch_iterate_async_param_2
)
{
	.reg .pred 	%p<8>;
	.reg .b16 	%rs<2>;
	.reg .b32 	%r<6>;
	.reg .b64 	%rd<25>;


	ld.param.u64 	%rd7, [dispatch_iterate_async_param_1];
	ld.param.u64 	%rd16, [dispatch_iterate_async_param_2];
	ld.u64 	%rd1, [%rd16];
	ld.u64 	%rd2, [%rd16+8];
	ld.u64 	%rd3, [%rd16+16];
	ld.u64 	%rd4, [%rd16+24];
	ld.u64 	%rd5, [%rd16+32];
	ld.u64 	%rd6, [%rd16+40];
	ld.u64 	%rd17, [%rd7];
	ld.u64 	%rd18, [%rd17+16];
	add.s64 	%rd8, %rd18, 36;
	ld.u32 	%r1, [%rd18+40];
	ld.u32 	%r2, [%rd18+36];
	mov.pred 	%p7, -1;
	mov.u64 	%rd23, 0;
	setp.ge.u32	%p4, %r2, %r1;
	@%p4 bra 	BB2_2;

	atom.add.u32 	%r3, [%rd8], 1;
	ld.u32 	%r4, [%rd8+4];
	setp.lt.u32	%p5, %r3, %r4;
	cvt.u64.u32	%rd19, %r3;
	selp.b64	%rd23, %rd19, 0, %p5;
	setp.ge.u32	%p7, %r3, %r4;

BB2_2:
	@%p7 bra 	BB2_7;

	ld.u64 	%rd20, [%rd7];
	ld.u64 	%rd11, [%rd20+16];
	ld.u8 	%rs1, [%rd11];
	setp.eq.s16	%p6, %rs1, 0;
	@%p6 bra 	BB2_5;

	ld.u64 	%rd24, [%rd11+8];
	bra.uni 	BB2_6;

BB2_5:
	ld.u64 	%rd24, [%rd11+16];

BB2_6:
	shl.b64 	%rd21, %rd23, 6;
	add.s64 	%rd22, %rd24, %rd21;
	st.u64 	[%rd22+8], %rd1;
	st.u64 	[%rd22+16], %rd2;
	st.u64 	[%rd22+24], %rd3;
	st.u64 	[%rd22+32], %rd4;
	st.u64 	[%rd22+40], %rd5;
	st.u64 	[%rd22+48], %rd6;

BB2_7:
	mov.u32 	%r5, 0;
	st.param.b32	[func_retval0+0], %r5;
	ret;
}

	// .globl	dispatch_iterate_sync
.visible .func  (.param .b32 func_retval0) dispatch_iterate_sync(
	.param .b64 dispatch_iterate_sync_param_0,
	.param .b64 dispatch_iterate_sync_param_1,
	.param .b64 dispatch_iterate_sync_param_2
)
{
	.local .align 8 .b8 	__local_depot3[104];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .b32 	%r<3>;
	.reg .b64 	%rd<21>;


	mov.u64 	%SPL, __local_depot3;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd1, [dispatch_iterate_sync_param_1];
	ld.param.u64 	%rd2, [dispatch_iterate_sync_param_2];
	add.u64 	%rd3, %SP, 0;
	add.u64 	%rd4, %SPL, 0;
	add.u64 	%rd5, %SP, 48;
	add.u64 	%rd6, %SPL, 48;
	add.u64 	%rd7, %SP, 96;
	add.u64 	%rd8, %SPL, 96;
	ld.u64 	%rd9, [%rd2];
	ld.u64 	%rd10, [%rd2+8];
	ld.u64 	%rd11, [%rd2+16];
	ld.u64 	%rd12, [%rd2+24];
	ld.u64 	%rd13, [%rd2+32];
	ld.u64 	%rd14, [%rd2+40];
	ld.u64 	%rd15, [%rd1];
	ld.u64 	%rd16, [%rd1+8];
	ld.u64 	%rd17, [%rd1+16];
	ld.u64 	%rd18, [%rd1+24];
	ld.u64 	%rd19, [%rd1+32];
	ld.u64 	%rd20, [%rd1+40];
	st.local.u64 	[%rd4], %rd15;
	st.local.u64 	[%rd4+8], %rd16;
	st.local.u64 	[%rd4+16], %rd17;
	st.local.u64 	[%rd4+24], %rd18;
	st.local.u64 	[%rd4+32], %rd19;
	st.local.u64 	[%rd4+40], %rd20;
	st.local.u64 	[%rd6], %rd9;
	st.local.u64 	[%rd6+8], %rd10;
	st.local.u64 	[%rd6+16], %rd11;
	st.local.u64 	[%rd6+24], %rd12;
	st.local.u64 	[%rd6+32], %rd13;
	st.local.u64 	[%rd6+40], %rd14;
	mov.u32 	%r1, 0;
	st.local.u32 	[%rd8], %r1;
	// Callseq Start 4
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd7;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd3;
	.param .b64 param2;
	st.param.b64	[param2+0], %rd5;
	.param .b32 retval0;
	call.uni (retval0), 
	_iterate, 
	(
	param0, 
	param1, 
	param2
	);
	ld.param.b32	%r2, [retval0+0];
	
	//{
	}// Callseq End 4
	st.param.b32	[func_retval0+0], %r1;
	ret;
}

	// .globl	access_device
.visible .func  (.param .b32 func_retval0) access_device(
	.param .b64 access_device_param_0,
	.param .b64 access_device_param_1
)
{
	.reg .b32 	%r<2>;
	.reg .b64 	%rd<5>;


	ld.param.u64 	%rd1, [access_device_param_0];
	ld.param.u64 	%rd2, [access_device_param_1];
	ld.u64 	%rd3, [%rd2+24];
	ld.u64 	%rd4, [%rd3];
	st.u64 	[%rd1], %rd4;
	mov.u32 	%r1, 0;
	st.param.b32	[func_retval0+0], %r1;
	ret;
}

	// .globl	access_group
.visible .func  (.param .b32 func_retval0) access_group(
	.param .b64 access_group_param_0,
	.param .b64 access_group_param_1
)
{
	.reg .b32 	%r<2>;
	.reg .b64 	%rd<5>;


	ld.param.u64 	%rd1, [access_group_param_0];
	ld.param.u64 	%rd2, [access_group_param_1];
	ld.u64 	%rd3, [%rd2+32];
	ld.u64 	%rd4, [%rd3];
	st.u64 	[%rd1], %rd4;
	mov.u32 	%r1, 0;
	st.param.b32	[func_retval0+0], %r1;
	ret;
}

	// .globl	access_thread
.visible .func  (.param .b32 func_retval0) access_thread(
	.param .b64 access_thread_param_0,
	.param .b64 access_thread_param_1
)
{
	.reg .b32 	%r<2>;
	.reg .b64 	%rd<5>;


	ld.param.u64 	%rd1, [access_thread_param_0];
	ld.param.u64 	%rd2, [access_thread_param_1];
	ld.u64 	%rd3, [%rd2+40];
	ld.u64 	%rd4, [%rd3];
	st.u64 	[%rd1], %rd4;
	mov.u32 	%r1, 0;
	st.param.b32	[func_retval0+0], %r1;
	ret;
}

	// .globl	_ZN4util14current_leaderEv
.visible .func  (.param .b32 func_retval0) _ZN4util14current_leaderEv(

)
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<9>;


	// inline asm
	activemask.b32 %r1;
	// inline asm
	neg.s32 	%r2, %r1;
	and.b32  	%r3, %r1, %r2;
	clz.b32 	%r4, %r3;
	mov.u32 	%r5, 31;
	sub.s32 	%r6, %r5, %r4;
	mov.u32 	%r7, %tid.x;
	setp.eq.s32	%p1, %r6, %r7;
	selp.u32	%r8, 1, 0, %p1;
	st.param.b32	[func_retval0+0], %r8;
	ret;
}

	// .globl	_ZN4util13warp_inc_scanEv
.visible .func  (.param .b32 func_retval0) _ZN4util13warp_inc_scanEv(

)
{
	.reg .b32 	%r<8>;


	// inline asm
	activemask.b32 %r1;
	// inline asm
	mov.u32 	%r2, %tid.x;
	mov.u32 	%r3, 1;
	shl.b32 	%r4, %r3, %r2;
	add.s32 	%r5, %r4, -1;
	and.b32  	%r6, %r5, %r1;
	popc.b32 	%r7, %r6;
	st.param.b32	[func_retval0+0], %r7;
	ret;
}

	// .globl	_ZN4util12active_countEv
.visible .func  (.param .b32 func_retval0) _ZN4util12active_countEv(

)
{
	.reg .b32 	%r<3>;


	// inline asm
	activemask.b32 %r1;
	// inline asm
	popc.b32 	%r2, %r1;
	st.param.b32	[func_retval0+0], %r2;
	ret;
}

	// .globl	_ZN4util9pop_countEj
.visible .func  (.param .b32 func_retval0) _ZN4util9pop_countEj(
	.param .b32 _ZN4util9pop_countEj_param_0
)
{
	.reg .b32 	%r<3>;


	ld.param.u32 	%r1, [_ZN4util9pop_countEj_param_0];
	popc.b32 	%r2, %r1;
	st.param.b32	[func_retval0+0], %r2;
	ret;
}

	// .globl	_ZN4util9pop_countEy
.visible .func  (.param .b64 func_retval0) _ZN4util9pop_countEy(
	.param .b64 _ZN4util9pop_countEy_param_0
)
{
	.reg .b32 	%r<2>;
	.reg .b64 	%rd<3>;


	ld.param.u64 	%rd1, [_ZN4util9pop_countEy_param_0];
	popc.b64 	%r1, %rd1;
	cvt.s64.s32	%rd2, %r1;
	st.param.b64	[func_retval0+0], %rd2;
	ret;
}

	// .globl	_ZN4util13leading_zerosEj
.visible .func  (.param .b32 func_retval0) _ZN4util13leading_zerosEj(
	.param .b32 _ZN4util13leading_zerosEj_param_0
)
{
	.reg .b32 	%r<3>;


	ld.param.u32 	%r1, [_ZN4util13leading_zerosEj_param_0];
	clz.b32 	%r2, %r1;
	st.param.b32	[func_retval0+0], %r2;
	ret;
}

	// .globl	_ZN4util13leading_zerosEy
.visible .func  (.param .b64 func_retval0) _ZN4util13leading_zerosEy(
	.param .b64 _ZN4util13leading_zerosEy_param_0
)
{
	.reg .b32 	%r<2>;
	.reg .b64 	%rd<3>;


	ld.param.u64 	%rd1, [_ZN4util13leading_zerosEy_param_0];
	clz.b64 	%r1, %rd1;
	cvt.s64.s32	%rd2, %r1;
	st.param.b64	[func_retval0+0], %rd2;
	ret;
}

	// .globl	_ZN4util11random_uintERj
.visible .func  (.param .b32 func_retval0) _ZN4util11random_uintERj(
	.param .b64 _ZN4util11random_uintERj_param_0
)
{
	.reg .b32 	%r<3>;
	.reg .b64 	%rd<2>;


	ld.param.u64 	%rd1, [_ZN4util11random_uintERj_param_0];
	ld.u32 	%r1, [%rd1];
	mad.lo.s32 	%r2, %r1, 69069, 1;
	st.u32 	[%rd1], %r2;
	st.param.b32	[func_retval0+0], %r2;
	ret;
}

	// .globl	_ZN4util11random_uintERy
.visible .func  (.param .b64 func_retval0) _ZN4util11random_uintERy(
	.param .b64 _ZN4util11random_uintERy_param_0
)
{
	.reg .b64 	%rd<5>;


	ld.param.u64 	%rd1, [_ZN4util11random_uintERy_param_0];
	ld.u64 	%rd2, [%rd1];
	mul.lo.s64 	%rd3, %rd2, 2971215073;
	add.s64 	%rd4, %rd3, 12345;
	st.u64 	[%rd1], %rd4;
	st.param.b64	[func_retval0+0], %rd4;
	ret;
}


